# What is "Data Quality" and why test for it?
Our Data Factory pipelines pull data from our client's OLTP databases.  Those databases have well-defined schema which define rules about how data is organized, how rows are stored in tables, and how rows are related to one another.  The queries we use to access that data are quite specific about which which rows to examine, which columns we pull, and how we join data from different tables.  But despite all those precise definitions; there is no way to account for the universe of possibilities which can and do exist in client data!  

In the month of April 2021 alone, we've seen the following data conditions: untranslated label text, unset cycle time columns, and missing invoice data.  Unfortunately, one of those issues was found by a client.  Due to our testing process, the other issues were found and dealt with before clients could notice.

As we get more and more clients onboarded; both the volume of data and the range of possibilities for weird data conditions increase - and thus the chances of things slipping through the cracks increases also.  Since problems like this would have a negative effect on the utility, quality, and trustworthiness of our application; a better way to find these issues before they go in front of customers eyes is a good idea.  If we can do it in an automated way each time we refresh the data, all the better.

# What exactly can we check?
As mentioned above, the number of things that could go wrong with our data is quite large, and quite unpredictable beforehand!  There is just no way we could design tests which would find and prevent all possible data errors.  That said, we do know what has gone wrong in the past - for example untranslated fields.  We know which columns are populated in separate parts of the pipeline and have different failure modes than the rest of the data - like cycle time.  We also know the assumptions about the data are made in our UI.  I haven't seen one like this yet; but let me give an example.  The data four our headcount metric is at the assignment detail level, meaning there are many rows for one assignment.  To get a headcount, our UI only counts the detail level rows where the "current row" flag is set.  This is only true for one detail record per assignment.  Or at least it should be!  If there is an assignment with TWO rows with the "current row" set to true, that one assignment will look like two assignments to our UI.  If there is a current assignment with NO rows having that set, that assignment will never be counted against headcount.  So our UI is only accurate if, per assignment, one and only one record is "current row" = true. This is currently true in our data - I assume its enforced by CWS application code; but if there is ever a CWS bug, or a change introduces a bug into our query, or somehow our pipeline's truncate and reload fails to truncate, this scenario could happen.  

So it will always be an incomplete list; but we can build tests to find and catch things which would diminish our UI experience.  And if we ever find some issue that slips through, we can add a new test for it so we'll get it next time!

# What features / behaviors do we want in a data checking system?
Here is a list of features/desires that we'll want in any data testing system we design.  Please feel free to comment on these or add more.

1. It should run as part of the normal refresh process.  Probably as the very last step.
1. Run checks as soon as possible; but not earlier!  After the rearrangement of activities last week, we should be able to run checks once per "mini-pipeline" for all clients.  For example, start the rate-card tests as soon as all ratecard data is pulled for all clients, even if spend data is still being processed.
1. If/when bad data is found do NOT fail the whole pipeline; but instead log the results and raise an Azure alert.  Its likely that one client might have bad data; but all others are fine, or one pipeline (Spend for example) has bad data; but others are fine.  For this reason, we don't want to mark the whole process as failed.  Perhaps fail the lowest level pipeline??
1. Make the process of adding a new query or modifying an old query easy.  Version control of these tests should be in git.  I'm not sure which repo - DF repo?  database repo? new repo?  But the goal is for it to be readable and NOT only in a DACPAC or DataFactory config json file.
1. Error messages when data problems are found should contain at least the following: which silo, which client, which test failed.  I think we should raised these as alerts, similar to how we alert on pipeline failures.
1. It would be nice to have a history of these alerts.  Would we log to the same place we do security scans?  Application Insights?  a new DB table?  Just DF history?  not sure.
1. If possible, run tests as the same user/credentials used during the PowerBI data pulls.  This would make these tests functionally similar to "integration tests" in many software build pipelines.
1. If possible, run tests against the views used during the PowerBI data pulls - not the base tables.  This is for similar reasons as above.  It makes the data tests similar to integration tests.

